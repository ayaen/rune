//  Copyright 2023 Google LLC.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// This implements a PEG parser, conforming closely to the description on
// http://wikipedia.org/wiki/Parsing_expression_grammar.  The only intentional
// difference is using '|' like all grammar languages other than PEG, instead of
// "/".  This parser uses the Rune lexer in lexer.rn to generate input tokens.
// The Wikipedia page shows tokens being parsed by regular expressions, but we
// have no regular expression library written in Rune, yet.
//
// Additional information is also encoded: "weak" keywords are in single
// quotes, while "strong" keywords are in double quotes.  Weak keywords are
// dropped from the parse tree.  Similarly, a ':' after a rule's name
// declares a "weak" rule, which a ':=' declares a "strong" rule.  Strong rules
// are not collapsed even if they have only one child node.
//
// With strong/weak keywords and rules, the resulting parse tree is a
// reasonable AST.
//
// For now, we're using the "direct left recursion" algorithm described in this
// paper: http://www.tinlizzie.org/~awarth/papers/pepm08.pdf.  Left recursion
// is only supported within the same rule.  If we need support for general
// left recursion, we can implement the full algorithm described in the paper.

import database as db
use keytab
use lexer
use sym
use token

root = db.getRoot()

// This corresponds to the Peg definition at
// https://en.wikipedia.org/wiki/Parsing_expression_grammar
enum PexprType {
  Nonterm
  Term  // This corresponds to a TokenType.
  Keyword
  Empty
  Sequence
  Choice
  ZeroOrMore
  OneOrMore
  Optional
  And  // Called And-predicated on Wikipedia.
  Not  // Called Not-predicated on Wikipedia.
}

struct Match {
  success: bool
  pos: u32
}

class Peg(self, fileName: string) {
  // Keyword table for parsing syntax rules file.
  self.pegKeytab = self.buildPegKeywordTable()
  // Keyword table for parsing input file.
  self.keytab = Keytab()
  // Used to report the first token we cannot parse.  We keep track of the most
  // progress made during parsing and report a syntax error at the first token
  // that cannot be parsed by any rule.
  self.maxTokenPos = 0u32
  self.savedToken1 = null(Token)
  self.savedToken2 = null(Token)
  self.numKeywords = 0u32
  self.initialized = false
  filepath = db.Filepath(fileName, null(db.Filepath), false)
  lexer = Lexer(filepath, self.pegKeytab)
  lexer.enableWeakStrings(true)
  self.insertLexer(lexer)

  // Parse a file using rules built by calling parseRules in the constructor.
  // It either succeeds or exits with an error.
  func parse(self: Peg, fileName: string, allowUnderscores: bool = false) -> Node? {
    if !self.initialized {
      self.addEOFToFirstRule()
      self.initialized = true
    }
    self.savedToken1 = null(Token)
    self.savedToken2 = null(Token)
    filepath = db.Filepath(fileName, null(db.Filepath), false)
    lexer = Lexer(filepath, self.keytab)
    lexer.enableIdentUnderscores(allowUnderscores)
    if !isnull(self.lexer) {
      self.lexer!.destroy()
    }
    self.insertLexer(lexer)
    self.tokenizeInput()
    if root.debugMode {
      println "Tokens:"
      for token in self.lexer!.tokens {
        token.dump()
      }
    }
    rule = self.firstOrderedRule!
    result = self.parseUsingRule(null(ParseResult), rule, 0u32)
    if !result.success {
      pos = min(self.maxTokenPos, <u32>self.lexer!.tokens.length() - 1)
      token = self.lexer!.tokens[pos]
      token.location.error("Syntax error")
      return null(Node)
    }
    parseResult = self.lexer!.firstParseResult!
// temp
// println "Final result"
// parseResult.dump()
    node = parseResult.buildParseTree()
    if root.debugMode || root.dumpParseTree {
      node.dump()
    }
    return node
  }

  // Reads all tokens up-front.
  func tokenizeInput(self: Peg) {
    do {
      token = self.parseToken()
      token.pexpr = null(Pexpr)
    } while !token.eof()
  }

  // Add the EOF token to the first rule.
  func addEOFToFirstRule(self: Peg) {
    goal = self.firstOrderedRule!
    pexpr = goal.pexpr!
    if pexpr.type != PexprType.Sequence {
      goal.removePexpr(pexpr)
      seqPexpr = Pexpr(PexprType.Sequence, pexpr.location)
      seqPexpr.insertChildPexpr(pexpr)
      goal.insertPexpr(seqPexpr)
      pexpr = seqPexpr
    }
    eofPexpr = Pexpr(PexprType.Term, pexpr.location)
    eofPexpr.tokenType = TokenType.Eof
    eofPexpr.sym = self.kwEof.sym
    pexpr.appendChildPexpr(eofPexpr);
  }

  // Parse input using the PEG rules.  Basically, use recursive decent.
  // Return a position > `pos` on success, and `pos` on failure.
  func parseUsingRule(self: Peg, parentParseResult: ParseResult?,
      rule: Rule, pos: u32) -> Match {
    parseResult = rule.findHashedParseResult(pos)
    if !isnull(parseResult) {
      if root.debugMode {
        println "Using prior result for ", rule.sym.name
      }
      if parseResult!.pending {
        parseResult!.foundRecursion = true
      } else if parseResult!.result.success && !isnull(parentParseResult) &&
          isnull(parseResult!.parentParseResult) {
        parentParseResult!.appendChildParseResult(parseResult!)
      }
      return parseResult!.result
    }
    token = self.lexer!.tokens[pos]
    if token.type == TokenType.Keyword {
      if !rule.firstKeywords[token.keyword!.num] {
        // Don't bother cacheing this decision.
        return Match(rule.canBeEmpty, pos)
      }
    } else if !rule.firstTokens[<u32>token.type] {
      // Don't bother cacheing this decision.
      return Match(rule.canBeEmpty, pos)
    }
    if root.debugMode {
      println "Parse using rule ", rule.sym.name
    }
    // For now, we're using the "direct left recursion" algorithm described in
    // this paper: http://www.tinlizzie.org/~awarth/papers/pepm08.pdf
    // Left recursion is only supported within the same rule.
    // Set the initial memo to false - this will stop recursive attempts to
    // apply this rule and allow subsequent rules to be tried.
    pres = ParseResult(parentParseResult, rule, pos, Match(false, pos))
    lastResult = Match(false, pos)
    do {
      pres.pending = true
      result = self.parseUsingPexpr(pres, rule.pexpr!, pos)
      pres.pending = false
      madeProgress = false
      if result.success && result.pos > lastResult.pos{
        madeProgress = true
        lastResult = result
        // Cache this result.
        pres.result = lastResult
        if pres.foundRecursion {
          pres = pushRecursiveParseResult(pres)
        }
      }
    } while madeProgress && pres.foundRecursion
    assert pres.result.success == lastResult.success
    if root.debugMode {
      println "Returning from rule ", rule.sym.name, " with ", result
    }
    return lastResult

    // Create a new ParseResult to hold the information on pres.  Make
    // pres its child so we can remember the recursive matches we've made.
    func pushRecursiveParseResult(pres: ParseResult) -> ParseResult {
      rule = pres.rule!
      rule.removeHashedParseResult(pres)
      parent = pres.parentParseResult
      if !isnull(parent) {
        parent!.removeChildParseResult(pres)
      }
      // Avoid passing data members to constructor of the same class that
      // are passed by reference!  This avoids a C Rune compiler bug.
      result = pres.result
      newPres = ParseResult(parent, rule, pres.pos, result)
      newPres.foundRecursion = pres.foundRecursion
      newPres.pending = pres.pending
      newPres.appendChildParseResult(pres)
      return newPres
    }
  }

  func parseUsingPexpr(self: Peg, parseResult: ParseResult, pexpr: Pexpr, pos: u32) -> Match {
    if root.debugMode {
      println "counter = ", db.getCounter(), ", pos = ", pos
    }
    db.incCounter()
    lastChild = parseResult.lastChildParseResult
    result = self.parseUsingPexprImpl(parseResult, pexpr, pos)
    if result.success && result.pos > self.maxTokenPos {
      self.maxTokenPos = result.pos
    }
    if !result.success {
      // Prune any successful ParseResults that we built before failing.
      do {
        child = parseResult.lastChildParseResult
      } while child != lastChild {
// temp
// if <u32>child! == 81 {
  // println "Removing child 81"
// }
        parseResult.removeChildParseResult(child!)
      }
    }
    if root.debugMode {
      println "Result = ", result
    }
    return result
  }

  // Parse input from pos using this pexpr.
  func parseUsingPexprImpl(self: Peg, parseResult: ParseResult, pexpr: Pexpr, pos: u32) -> Match {
    token = self.lexer!.tokens[pos]
    if root.debugMode {
      token.location.dump()
      println "Parsing above token using ", pexpr.toString()
    }
    switch pexpr.type {
      PexprType.Nonterm => return self.parseUsingRule(parseResult, pexpr.nontermRule!, pos)
      PexprType.Term => {
        if token.type != pexpr.tokenType {
          return Match(false, pos)
        }
        token.pexpr = pexpr
        return Match(true, pos + 1)
      }
      PexprType.Keyword => {
        if token.type != TokenType.Keyword || token.keyword! != pexpr.keyword! {
          return Match(false, pos)
        }
        token.pexpr = pexpr
        return Match(true, pos + 1)
      }
      PexprType.Empty => return Match(true, pos)
      PexprType.Sequence => return self.parseUsingSequencePexpr(parseResult, pexpr, pos)
      PexprType.Choice =>  return self.parseUsingChoicePexpr(parseResult, pexpr, pos)
      PexprType.ZeroOrMore => return self.parseUsingZeroOrMorePexpr(parseResult, pexpr, pos)
      PexprType.OneOrMore => return self.parseUsingOneOrMorePexpr(parseResult, pexpr, pos)
      PexprType.Optional => return self.parseUsingOptionalPexpr(parseResult, pexpr, pos)
      PexprType.And => return self.parseUsingAndPexpr(parseResult, pexpr, pos)
      PexprType.Not => return self.parseUsingNotPexpr(parseResult, pexpr, pos)
    }
  }

  func parseUsingSequencePexpr(self: Peg, parseResult: ParseResult, pexpr, pos) -> Match {
    childPos = pos
    for child in pexpr.childPexprs() {
      result = self.parseUsingPexpr(parseResult, child, childPos)
      if !result.success {
        return Match(false, pos)
      }
      childPos = result.pos
      if <u64>childPos == self.lexer!.tokens.length() {
        return result
      }
    }
    return result
  }

  func parseUsingChoicePexpr(self: Peg, parseResult: ParseResult, pexpr, pos) -> Match {
    for child in pexpr.childPexprs() {
      result = self.parseUsingPexpr(parseResult, child, pos)
      if result.success {
        return result
      }
    }
    return Match(false, pos)
  }

  func parseUsingZeroOrMorePexpr(self: Peg, parseResult: ParseResult, pexpr, pos) -> Match {
    child = pexpr.firstChildPexpr!
    lastResult = Match(true, pos)
    do {
      result = self.parseUsingPexpr(parseResult, child, lastResult.pos)
    } while result.success {
      lastResult = result
    }
    return lastResult
  }

  func parseUsingOneOrMorePexpr(self: Peg, parseResult: ParseResult, pexpr, pos) -> Match {
    child = pexpr.firstChildPexpr!
    lastResult = Match(false, pos)
    do {
      result = self.parseUsingPexpr(parseResult, child, lastResult.pos)
    } while result.success {
      lastResult = result
    }
    return lastResult
  }

  func parseUsingOptionalPexpr(self: Peg, parseResult: ParseResult, pexpr, pos) -> Match {
    child = pexpr.firstChildPexpr!
    result = self.parseUsingPexpr(parseResult, child, pos)
    if result.success {
      return result
    }
    return Match(true, pos)
  }

  func parseUsingAndPexpr(self: Peg, parseResult: ParseResult, pexpr, pos) -> Match {
    child = pexpr.firstChildPexpr!
    result = self.parseUsingPexpr(parseResult, child, pos)
    return Match(result.success, pos)
  }

  func parseUsingNotPexpr(self: Peg, parseResult: ParseResult, pexpr, pos) -> Match {
    child = pexpr.firstChildPexpr!
    result = self.parseUsingPexpr(parseResult, child, pos)
    return Match(!result.success, pos)
  }

  // Recursive decent parser for rules, using the `Lexer` class.
  func parseRules(self: Peg) {
    // Weak strings are keywords assumed to be syntax that are not needed in
    // the parse tree.  The parse tree will leave them out.
    self.lexer!.enableWeakStrings(true);
    while !self.lexer!.eof() {
      self.parseRule()
    }
    self.numKeywords = self.keytab!.setKeywordNums()
    passed = self.bindNonterms()
    if !self.checkForUnusedRules() {
      passed = false
    }
    self.findFirstSets()
    if !passed {
      raise Status.InvalidArgument, "Exiting due to errors..."
    }
  }

  func parseRule(self: Peg) -> Rule {
    identToken = self.parseIdent()
    token = self.parseToken()
    if token.type != TokenType.Keyword || (token.keyword! != self.kwColon &&
      token.keyword! != self.kwColonEquals) {
      self.syntaxError()
    }
    pexpr = self.parsePexpr()
    if !self.endOfRule() {
      self.syntaxError()
    }
    rule = Rule(self, identToken.value!.symVal!, pexpr, identToken.location)
    rule.weak = token.keyword! == self.kwColon
    return rule
  }

  func parseIdent(self: Peg) -> Token {
    token = self.parseToken()
    if token.type != TokenType.Ident {
      self.syntaxError()
    }
    return token
  }

  func parsePexpr(self: Peg) -> Pexpr {
    return self.parseChoicePexpr()
  }

  func parseChoicePexpr(self: Peg) -> Pexpr {
    choicePexpr = null(Pexpr)
    do {
      pexpr = self.parseSequencePexpr()
      nextToken = self.peekToken()
    } while nextToken.type == TokenType.Keyword && nextToken.keyword! == self.kwPipe {
      if isnull(choicePexpr) {
        choicePexpr = Pexpr(PexprType.Choice, pexpr.location)
      }
      choicePexpr!.appendChildPexpr(pexpr)
      self.parseToken()
    }
    if isnull(choicePexpr) {
      return pexpr
    }
    choicePexpr!.appendChildPexpr(pexpr)
    return choicePexpr!
  }

  func parseSequencePexpr(self: Peg) -> Pexpr {
    pexpr = self.parsePrefixPexpr()
    if self.endOfRule() {
      return pexpr
    }
    if self.endOfSequence() {
      return pexpr
    }
    sequencePexpr = Pexpr(PexprType.Sequence, pexpr.location)
    sequencePexpr.appendChildPexpr(pexpr)
    while !self.endOfSequence() {
      pexpr = self.parsePrefixPexpr()
      sequencePexpr.appendChildPexpr(pexpr)
    }
    return sequencePexpr
  }

  func endOfSequence(self: Peg) -> bool {
    if self.endOfRule() {
      return true
    }
    token = self.peekToken()
    switch token.type {
      TokenType.Keyword => {
        keyword = token.keyword!
        return keyword == self.kwPipe || keyword == self.kwCloseParen
      }
      TokenType.Ident, TokenType.String, TokenType.WeakString => return false
      TokenType.Eof => return true
    }
  }

  func parsePrefixPexpr(self: Peg) -> Pexpr {
    token = self.peekToken()
    if token.type == TokenType.Keyword {
      keyword = token.keyword!
      if keyword == self.kwAnd || keyword == self.kwNot {
        self.parseToken()
        pexpr = self.parsePostfixPexpr()
        if keyword == self.kwAnd {
          return self.unaryPexpr(PexprType.And, pexpr, token.location)
        }
        return self.unaryPexpr(PexprType.Not, pexpr, token.location)
      }
    }
    return self.parsePostfixPexpr()
  }

  func parsePostfixPexpr(self: Peg) -> Pexpr {
    pexpr = self.parseBasicPexpr()
    if self.endOfRule() {
      return pexpr
    }
    token = self.peekToken()
    if token.type == TokenType.Keyword {
      keyword = token.keyword!
      if keyword == self.kwQuestion {
        self.parseToken()
        return self.unaryPexpr(PexprType.Optional, pexpr, token.location)
      } else if keyword == self.kwStar {
        self.parseToken()
        return self.unaryPexpr(PexprType.ZeroOrMore, pexpr, token.location)
      } else if keyword == self.kwPlus {
        self.parseToken()
        return self.unaryPexpr(PexprType.OneOrMore, pexpr, token.location)
      }
    }
    return pexpr
  }

  func parseBasicPexpr(self: Peg) -> Pexpr {
    token = self.parseToken()
    if token.type == TokenType.Ident {
      pexpr = Pexpr(PexprType.Nonterm, token.location)
      pexpr.sym = token.value!.symVal!
      return pexpr
    } else if token.type == TokenType.String || token.type == TokenType.WeakString {
      pexpr = Pexpr(PexprType.Keyword, token.location)
      name = token.value!.stringVal
      pexpr.weak = token.type == TokenType.WeakString
      pexpr.sym = Sym.new(name)
      keyword = self.keytab.new(name)
      keyword.appendPexpr(pexpr)
      return pexpr
    } else if token.type == TokenType.Keyword {
      keyword = token.keyword!
      if keyword == self.kwEmpty {
        return Pexpr(PexprType.Empty, token.location)
      } else if keyword == self.kwOpenParen {
        return self.parseParenPexpr()
      }
      pexpr = Pexpr(PexprType.Term, token.location)
      pexpr.tokenType = self.keywordToTokenType(keyword, token.location)
      pexpr.sym = token.keyword!.sym
      return pexpr
    }
    self.syntaxError()
    panic "Can't get here"
  }

  func parseParenPexpr(self: Peg) -> Pexpr {
    pexpr = self.parsePexpr()
    token = self.parseToken()
    if token.type != TokenType.Keyword || token.keyword! != self.kwCloseParen {
      token.location.error("Expected ')'")
    }
    pexpr.hasParens = true
    return pexpr
  }

  func unaryPexpr(self: Peg, type: PexprType, pexpr: Pexpr, location: db.Location) -> Pexpr {
    parentPexpr = Pexpr(type, location)
    parentPexpr.insertChildPexpr(pexpr)
    return parentPexpr
  }

  func syntaxError(self: Peg) {
    self.lexer!.error("Syntax error")
  }

  func endOfRule(self: Peg) {
    if self.lexer!.eof() {
      return true
    }
    token = self.peekToken(2)
    return token.type == TokenType.Keyword && (token.keyword! == self.kwColon ||
        token.keyword! == self.kwColonEquals)
  }

  func parseToken(self: Peg) -> Token {
    if !isnull(self.savedToken1) {
      token = self.savedToken1!
      self.savedToken1 = self.savedToken2
      self.savedToken2 = null(Token)
      return token
    }
    return self.rawParseToken()
  }

  func rawParseToken(self: Peg) -> Token {
    do {
      token = self.lexer!.parseToken()
    } while token.type == TokenType.Keyword && token.keyword! == self.kwNewline
    if root.debugMode {
      token.dump()
    }
    return token
  }

  func peekToken(self: Peg, depth = 1) -> Token {
    assert depth <= 2
    if depth >= 1 && isnull(self.savedToken1) {
      self.savedToken1 = self.rawParseToken()
    }
    if depth >= 2 && isnull(self.savedToken2) {
      self.savedToken2 = self.rawParseToken()
    }
    return depth == 1? self.savedToken1! : self.savedToken2!
  }

  func buildPegKeywordTable(self: Peg) -> Keytab {
    keytab = Keytab()
    self.kwColon = Keyword(keytab, ":")
    self.kwColonEquals = Keyword(keytab, ":=")
    self.kwPipe = Keyword(keytab, "|")
    self.kwOpenParen = Keyword(keytab, "(")
    self.kwCloseParen = Keyword(keytab, ")")
    self.kwStar = Keyword(keytab, "*")
    self.kwPlus = Keyword(keytab, "+")
    self.kwQuestion = Keyword(keytab, "?")
    self.kwAnd = Keyword(keytab, "&")
    self.kwNot = Keyword(keytab, "!")
    self.kwNewline = Keyword(keytab, "\n")
    self.kwEmpty = Keyword(keytab, "EMPTY")
    self.kwEof = Keyword(keytab, "EOF")
    self.kwIdent = Keyword(keytab, "IDENT")
    self.kwInteger = Keyword(keytab, "INTEGER")
    self.kwFloat = Keyword(keytab, "FLOAT")
    self.kwString = Keyword(keytab, "STRING")
    self.kwRandInt = Keyword(keytab, "RANDUINT")
    self.kwIntType = Keyword(keytab, "INTTYPE")
    self.kwUintType = Keyword(keytab, "UINTTYPE")
    return keytab
  }

  func keywordToTokenType(self, keyword: Keyword, location: db.Location) -> TokenType {
    switch keyword {
      self.kwEof => return TokenType.Eof
      self.kwIdent => return TokenType.Ident
      self.kwInteger => return TokenType.Integer
      self.kwFloat => return TokenType.Float
      self.kwString => return TokenType.String
      self.kwRandInt => return TokenType.RandUint
      self.kwIntType => return TokenType.IntType
      self.kwUintType => return TokenType.UintType
      default => {
        location.error("Syntax error")
        raise Status.InvalidArgument
      }
    }
  }

  // Fill in Rule -> NontermPexpr relation.  This has to wait until afer
  // parsing because the rule a nonterm refers to may not be declared before
  // the nonterm.
  func bindNonterms(self: Peg) -> bool{
    passed = true
    for rule in self.orderedRules() {
      if !self.bindPexprNonterms(rule.pexpr!) {
        passed = false
      }
    }
    return passed
  }

  // Bind all the nonterms in the pexpr to their rule.
  func bindPexprNonterms(self: Peg, pexpr: Pexpr) -> bool {
    passed = true
    if pexpr.type == PexprType.Nonterm {
      rule = self.findRule(pexpr.sym!)
      if isnull(rule) {
         pexpr.location.error("Undefined rule " + pexpr.sym!.name)
         passed = false
      }
      rule!.appendNontermPexpr(pexpr)
    }
    for child in pexpr.childPexprs() {
      if !self.bindPexprNonterms(child) {
        passed = false
      }
    }
    return passed
  }

  // Find the set of tokens that could be seen first for the rule.  Also detect
  // and report left-recursion.
  func findFirstSets(self) {
    for rule in self.orderedRules() {
      if !rule.firstSetFound {
        rule.findFirstSet()
      }
    }
  }

  func checkForUnusedRules(self) -> bool {
    passed = true
    firstTime = true
    for rule in self.orderedRules() {
      if !firstTime {
        if isnull(rule.firstNontermPexpr) && !isnull(rule.peg)  {
          rule.location.error("Unused rule " + rule.sym!.name)
          passed = false
        }
      }
      firstTime = false
    }
    return passed
  }

  func toString(self: Peg) -> string {
    s = ""
    for rule in self.orderedRules() {
      s.concat(rule.toString())
      s.append('\n')
    }
    return s
  }

  exportlib func dump(self: Peg) {
    println self.toString()
  }
}

class ParseResult(self, parentParseResult: ParseResult?, rule: Rule, pos: u32, result: Match) {
  self.pos = pos
  self.result = result
  self.foundRecursion = false
  self.pending = false
  rule.insertHashedParseResult(self)
  rule.appendParseResult(self)
  // Add it to the lexer so we can destroy this result when the lexer is destroyed.
  if !isnull(parentParseResult) {
    parentParseResult!.appendChildParseResult(self)
    prevChild = self.prevParseResultChildParseResult
    if !isnull(prevChild) {
      assert prevChild!.result.success && prevChild!.result.pos <= self.pos
    }
  }
  lexer = rule.peg!.lexer!
  lexer.appendParseResult(self)

  func buildParseTree(self: ParseResult) -> Node {
    parentNode = null(Node)
    parent = self.parentParseResult
    if !isnull(parent) {
      parentNode = parent!.node!
    }
    node = Node(parentNode, self, self.pos, self.result.pos)
    pos = self.pos
    for child in self.childParseResults() {
      self.addNodeTokens(pos, child.pos)
      child.buildParseTree()
      pos = child.result.pos
    }
    self.addNodeTokens(pos, self.result.pos)
    node.simplify()
    return node
  }

  // Append the tokens in the range to the node.
  func addNodeTokens(self: ParseResult, startPos: u32, endPos: u32) {
    lexer = self.rule!.peg!.lexer!
    node = self.node!
    for pos in range(startPos, endPos) {
      token = lexer.tokens[pos]
      pexpr = token.pexpr!
      if !pexpr.weak {
        Node(node, null(ParseResult), pos, pos + 1, token)
      }
    }
  }

  func dump(self: ParseResult) {
    self.dumpIndented(0u32)
  }

  func dumpIndented(self: ParseResult, depth: u32) {
    print indent(depth)
    println self.rule!.sym.name, " <", <u32>self, ">"
    for child in self.childParseResults() {
      child.dumpIndented(depth + 1)
    }
  }
}

// This is the AST class, which is a simplified version of ParseResult, which encodes the parse tree.
class Node(self, parent: Node?, parseResult: ParseResult?, startPos: u32, endPos: u32, token: Token? = null(Token)) {
  self.startPos = startPos
  self.endPos = endPos
  self.token = token
  if !isnull(parent) {
    parent!.appendChildNode(self)
  }
  if !isnull(parseResult) {
    parseResult!.insertNode(self)
  }

  // Return the symbol for the rule this node matches, if it does match a rule.
  // Otherwise return null(Sym).
  func getRuleSym(self: Node) -> Sym? {
    if isnull(self.parseResult) {
      return null(Sym)
    }
    return self.parseResult!.rule!.sym
  }

  func simplify(self: Node) {
    for child in self.safeChildNodes() {
      if isnull(child.firstChildNode) {
        token = child.token
        rule = null(Rule)
        if !isnull(child.parseResult) {
          rule = child.parseResult!.rule
        }
        if (isnull(rule) || rule!.weak) && (isnull(token) || token!.pexpr!.weak) {
          child!.destroy()
        }
      }
    }
    firstChild = self.firstChildNode
    if !isnull(firstChild) && firstChild == self.lastChildNode {
      self.mergeChildNode()
    }
  }

  // Merge this node's sole child into this node, unless both represent
  // strong rules.  If only one represents a strong rule, keep that one.
  func mergeChildNode(self: Node) {
    child = self.firstChildNode!
    parentRule = null(Rule)
    childRule = null(Rule)
    parentParseResult = self.parseResult
    childParseResult = child.parseResult
    if !isnull(parentParseResult) {
      parentRule = parentParseResult!.rule!
    }
    if !isnull(childParseResult) {
      childRule = childParseResult!.rule!
    }
    if !isnull(parentRule) && !parentRule!.weak && !isnull(childRule) && !childRule!.weak {
      return  // Don't merge strong nodes.
    }
    for node in child.safeChildNodes() {
      child.removeChildNode(node)
      self.appendChildNode(node)
    }
    self.token = child.token
    if !isnull(childRule) && !childRule!.weak {
      if !isnull(parentParseResult) {
        parentParseResult!.removeNode(self)
      }
      childParseResult!.removeNode(child)
      childParseResult!.insertNode(self)
    }
    child.destroy()
  }

  func dump(self: Node) {
    println self.toString()
  }

  func toString(self: Node) -> string {
    printSpace = false
    return self.toStringIndented(0u32, printSpace)
  }

  func toStringIndented(self: Node, depth: u32, var printSpace: bool) -> string {
    s = ""
    needsParen = !isnull(self.firstChildNode)
    rule = null(Rule)
    if !isnull(self.parseResult) {
      rule = self.parseResult!.rule
    }
    if !isnull(rule) && !rule!.weak {
      s.append('\n')
      printSpace = false
      s.concat(indent(depth))
      s.concat(rule!.sym.name)
      needsParen = true
    }
    if needsParen {
      if printSpace {
        s.append(' ')
        printSpace = false
      }
      s.append('(')
    }
    if !isnull(self.token) {
      token = self.token!
      if printSpace {
        s.append(' ')
      }
      isStrongKeyword = token.type == TokenType.Keyword && !token.pexpr!.weak
      if isStrongKeyword {
        s.append('"')
      }
      s.concat(token.getName())
      if isStrongKeyword {
        s.append('"')
      }
      printSpace = true
    } else {
      for child in self.childNodes() {
        s.concat(child.toStringIndented(depth + 1, printSpace))
      }
    }
    if needsParen {
      s.append(')')
      printSpace = true
    }
    return s
  }
}

func indent(depth: u32) -> string {
  s = ""
  s.resize(depth << 1)
  for i in range(depth << 1) {
    s[i] = ' '
  }
  return s
}

class Rule(self, parser: Peg, sym: Sym, pexpr: Pexpr, location: db.Location) {
  self.sym = sym
  self.location = location
  self.insertPexpr(pexpr)
  // Indexed by the keyword number.
  self.firstKeywords = arrayof(bool)
  // Indexed by the token type.
  self.firstTokens = arrayof(bool)
  self.firstTokens.resize(<u32>TokenType.UintType + 1)
  self.firstSetFound = false
  self.findingFirstSet = false  // Used for loop detection.
  self.canBeEmpty = false
  self.weak = false
  oldRule = parser.findRule(sym)
  if isnull(oldRule) {
    parser.insertRule(self)
  } else {
    location.error("Redefinition of rule " + sym.name)
  }
  parser.appendOrderedRule(self)

  // Find the set of tokens that could be seen first for the rule.  Also detect
  // and report left-recursion.  Return false if we found a loop.
  func findFirstSet(self) {
    self.firstKeywords.resize(self.peg!.numKeywords)
    if self.findingFirstSet {
      return
    }
    self.findingFirstSet = true
    self.pexpr!.findFirstSet(self.firstKeywords, self.firstTokens)
    self.firstSetFound = true
    self.findingFirstSet = false
    self.canBeEmpty = self.pexpr!.canBeEmpty
  }

  func toString(self: Rule) -> string {
    s = self.sym.name
    s.concat(": ")
    s.concat(self.pexpr!.toString())
    return s
  }

  exportlib func dump(self: Rule) {
    println self.toString()
  }
}

// A parser expression.  Each rule has just one.
class Pexpr(self, type: PexprType, location: db.Location) {
  self.type = type
  self.location = location
  self.sym = null(Sym)  // Used for keywords in quotes, and nonterms.
  self.TokenType = TokenType.Keyword  // Used for Term pexprs, like INTEGER.
  self.hasParens = false
  self.canBeEmpty = false
  // If true on a keyword pexpr, don't include the keyword in the parse tree.
  // E.g "secret" '(' expr ')' will become ("secret" expr), not ("secret" "(" expr ")").
  self.weak = false
  self.nextChoice = arrayof(Pexpr)

  func findFirstSet(self: Pexpr, firstKeywords: [bool], firstTokens: [bool]) {
    switch self.type {
      PexprType.Nonterm => {
        // The first set of a nonterminal is the first set of the nonterminal's
        // rule.
        rule = self.nontermRule!
        if !rule.firstSetFound {
          rule.findFirstSet()
        }
        for i in range(rule.firstKeywords.length()) {
          firstKeywords[i] ||= rule.firstKeywords[i]
        }
        for i in range(rule.firstTokens.length()) {
          firstTokens[i] ||= rule.firstTokens[i]
        }
        self.canBeEmpty = rule.canBeEmpty
      }
      PexprType.Term => firstTokens[<u32>self.tokenType] = true
      PexprType.Keyword => firstKeywords[self.keyword!.num] = true
      PexprType.Empty, PexprType.And, PexprType.Not => self.canBeEmpty = true
      PexprType.Sequence => {
        for child in self.childPexprs() {
          child.findFirstSet(firstKeywords, firstTokens)
          if !child.canBeEmpty {
            return
          }
        }
        self.canBeEmpty = true
      }
      PexprType.Choice => {
        for child in self.childPexprs() {
          child.findFirstSet(firstKeywords, firstTokens)
          if child.canBeEmpty {
            self.canBeEmpty = true
          }
        }
      }
      PexprType.ZeroOrMore, PexprType.Optional => {
        self.canBeEmpty = true
        self.firstChildPexpr!.findFirstSet(firstKeywords, firstTokens)
      }
      PexprType.OneOrMore => {
        child = self.firstChildPexpr!
        child.findFirstSet(firstKeywords, firstTokens)
        self.canBeEmpty = child.canBeEmpty
      }
    }
  }

  func rawToString(self: Pexpr) -> string {
    switch(self.type) {
      PexprType.Nonterm => return self.sym!.name
      PexprType.Term => return self.sym!.name
      PexprType.Empty => return "EMPTY"
      PexprType.Keyword => return "\"%s\"" % self.sym!.name
      PexprType.Sequence => {
        s = ""
        firstTime = true
        for child in self.childPexprs() {
          if child.type != PexprType.Term || child.tokenType != TokenType.Eof {
            if !firstTime {
              s.append(' ')
            }
            firstTime = false
            s.concat(child.toString())
          }
        }
        return s
      }
      PexprType.Choice => {
        s = ""
        firstTime = true
        for child in self.childPexprs() {
          if !firstTime {
            s.concat(" | ")
          }
          firstTime = false
          s.concat(child.toString())
        }
        return s
      }
      PexprType.ZeroOrMore => return self.firstChildPexpr!.toString() + "*"
      PexprType.OneOrMore => return self.firstChildPexpr!.toString() + "+"
      PexprType.Optional => return self.firstChildPexpr!.toString() + "?"
      PexprType.And => return "&" + self.firstChildPexpr!.toString()
      PexprType.Not => return "!" + self.firstChildPexpr!.toString()
      default => {
        panic "Unexpected type = ", self.type
      }
    }
  }

  func toString(self: Pexpr) -> string {
    s = self.rawToString()
    if !self.hasParens {
      return s
    }
    return "(" + s + ")"
  }

  exportlib func dump(self: Pexpr) {
    println self.toString()
  }
}

relation Hashed Peg Rule cascade ("sym")
relation TailLinked Peg:"Ordered" Rule:"Ordered"
relation OneToOne Rule Pexpr cascade
relation TailLinked Keyword Pexpr cascade
relation TailLinked Pexpr:"Parent" Pexpr:"Child" cascade
relation TailLinked Rule:"Nonterm" Pexpr:"Nonterm"cascade
relation Hashed Rule:"Hashed" ParseResult:"Hashed" cascade ("pos")
relation DoublyLinked Rule ParseResult cascade
relation DoublyLinked Lexer ParseResult cascade
relation DoublyLinked ParseResult:"Parent" ParseResult:"Child"
relation OneToOne Peg Lexer cascade
relation OneToOne ParseResult Node cascade
relation DoublyLinked Node:"Parent" Node:"Child" cascade

unittest {
  import io

  xArg = 1
  while xArg < argv.length() && argv[xArg][0] == '-' {
    if argv[xArg] == "-d" || argv[xArg] == "--debug" {
      debugMode = true
      xArg += 1
    } else if argv[xArg] == "--parseTree" {
      root.dumpParseTree = true
      xArg += 1
    } else {
      println "Usage: ", argv[0], " [-d|--debug|--parseTree] [runeFile...]"
      exit(1i32)
    }
  }

  dataDir = io.getenv("TEST_SRCDIR")
  if dataDir != "" {
    if dataDir[dataDir.length() - 1] != '/' {
      dataDir.append('/')
    }
    dataDir.concat("google3/third_party/rune/bootstrap/parse/")
  }
}

// For manual testing of parsing Rune files listed in the command line.
unittest parseFilesOnCommandLiineTest {
  parsedAFile = false
  if xArg < argv.length() {
    parser = Peg(dataDir + "rune.syn")
    parser.parseRules()
    for i in range (xArg, argv.length()) {
      println "Parsing ", argv[i]
      parseResult = parser.parse(argv[i], allowUnderscores = true)
      if !!isnull(parseResult) {
        exit(1i32)
      }
      parsedAFile = true
    }
  }
  if parsedAFile {
    // Don't bother continuing with the rest of the unit tests.
    exit(0i32)
  }
}

// Parse syntax files in testdata, and verify we can print them out and be
// identical to what we read.
unittest parseRulesTest {
  tests = [
      "testdata/non_lalr.syn",
      "testdata/allOperators.syn"
  ]
  for test in tests {
    parser = Peg(dataDir + test)
    parser.parseRules()
    s = parser.toString()
    println s
    assert s == parser.lexer!.filepath!.text
  }
  println "passed parseExampleRulesTest"
}

unittest parseRuneRulesTest {
  parser = Peg(dataDir + "rune.syn")
  parser.parseRules()
  println "passed parseRuneRulesTest"
}

unittest parseFactorialFunctionTest {
  parser = Peg(dataDir + "rune.syn")
  parser.parseRules()
  parser.parse(dataDir + "testdata/factorial.rn")
  println "passed parseFactorialFunctionTest"
}

unittest parseSyntaxErrorTest {
  parser = Peg(dataDir + "rune.syn")
  parser.parseRules()
  node = parser.parse(dataDir + "testdata/syntaxError.rn")
  assert isnull(node)
  println "passed parseSyntaxErrorTest"
}

unittest reuseParseResultTest {
  parser = Peg(dataDir + "rune.syn")
  parser.parseRules()
  node = parser.parse(dataDir + "testdata/reuseParseResult.rn")
  assert !isnull(node)
  s = node!.toString()
  println s
  println "passed reuseParseResultTest"
}

// Test basic left-recursive parsing expression.
unittest testLeftRecursion {
  parser = Peg(dataDir + "testdata/leftRecursion.syn")
  parser.parseRules()
  node = parser.parse(dataDir + "testdata/expr.txt")
  assert !isnull(node)
  s = node!.toString()
  println s
  println "passed testLeftRecursion"
}

// Test left-recursive operators in Rune.
unittest testRuneLeftRecursion {
  parser = Peg(dataDir + "rune.syn")
  parser.parseRules()
  node = parser.parse(dataDir + "testdata/leftRecursion.rn")
  assert !isnull(node)
  s = node!.toString()
  println s
  println "passed testRuneLeftRecursion"
}
