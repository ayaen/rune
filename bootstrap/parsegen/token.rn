//  Copyright 2023 Google LLC.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import database.bigint as bi
import database.location as loc
import database.value as val
use keytab
use sym

enum TokenType {
  Nonterm
  Keyword
  Ident
  Integer
  Float
  Bool
  String
  Eof
  RandInt
  IntType
  UintType
}

class Token(self, type: TokenType, location: loc.Location, keyword: Keyword? = null(Keyword),
    value: val.Value? = null(val.Value)) {
  self.type = type
  self.location = location
  // We should use a tagged union here.
  if !isnull(keyword) {
    keyword!.appendToken(self)
  }
  self.value = value

  // Pass in the text from the lexer.
  func dump(self) {
    self.location.dump()
  }

  // Return true if this is the eof token.
  func eof(self) {
    return self.type == TokenType.eof
  }

  // Create a new token from a value.  This works for values like 123u8, and
  // also for identifiers which are parsed as Sym values, and keywords.
  func newValueToken(value: string | bool | Int | Uint | bi.Bigint | Float | Sym | Keyword,
      location: loc.Location) -> Token {
    typeswitch value {
      string => return Token(TokenType.String, location, value = val.Value(value))
      bool => return Token(TokenType.Bool, location, value = val.Value(value))
      Int, Uint, bi.Bigint => return Token(TokenType.Integer, location, value = val.Value(value))
      Float => return Token(TokenType.Float, location, value = val.Value(value))
      Sym  => return Token(TokenType.Ident, location, value = val.Value(value))
      Keyword  => return Token(TokenType.Keyword, location, keyword = value)
    }
  }
}

relation DoublyLinked Keyword Token cascade

unittest dumpTest {
  filepath = fp.Filepath.new("test_filepath", null(fp.Filepath), false)
  filepath.text = "first line\nsecond line"
  token1 = Token(TokenType.Ident, loc.Location(filepath, 0u32, 5u32, 1u32))
  token2 = Token(TokenType.Ident, loc.Location(filepath, 6u32, 4u32, 1u32))
  newline = Token(TokenType.Keyword, loc.Location(filepath, 10u32, 1u32, 1u32))
  token3 = Token(TokenType.Ident, loc.Location(filepath, 11u32, 6u32, 2u32))
  token4 = Token(TokenType.Ident, loc.Location(filepath, 18u32, 4u32, 2u32))
  token1.dump()
  token2.dump()
  newline.dump()
  token3.dump()
  token4.dump()
}

unittest {
  // Unnamed unit tests declare stuff common to all unit tests in the file.
  import database.filepath as fp
}

unittest eofTest {
  filepath = fp.Filepath.new("test_filepath", null(fp.Filepath), false)
  token = Token(TokenType.Eof, loc.Location(filepath, 0u32, 0u32, 1u32))
  assert token.type == TokenType.Eof
}

unittest newValueTokenTest {
  filepath = fp.Filepath.new("test_filepath", null(fp.Filepath), false)
  location = loc.Location(filepath, 0u32, 0u32, 1u32)
  println Token.newValueToken("string token", location)
  println Token.newValueToken(true, location)
  println Token.newValueToken(123i8, location)
  println Token.newValueToken(123456789, location)
  println Token.newValueToken(bi.Bigint(123), location)
  println Token.newValueToken(3.14, location)
  println Token.newValueToken(Sym.new("identifier"), location)
  keytab = Keytab()
  println Token.newValueToken(Keyword(keytab, "keyword"), location)
}
