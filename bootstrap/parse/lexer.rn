//  Copyright 2023 Google LLC.
//
// Licensed under the Apache License, Version 2.0 (the "License")
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// This will likely become the Rune lexer.  For now, it is only lexing syntax files.

import io
use sym

import database as db
use char
use keytab
use token

class Lexer(self, filepath: db.Filepath, keytab: Keytab, readFile: bool = true) {
  if filepath.text.length() == 0 {
    if readFile {
      filepath.readFile()
    }
  }
  self.pos = 0u32
  self.len = <u32>filepath.text.length()
  self.line = 1u32
  self.allowIdentUnderscores = false
  self.useWeakStrings = false
  self.startPos = 0u32
  self.keytab = keytab
  self.tokens = arrayof(Token)
  filepath.insertLexer(self)

  func enableIdentUnderscores(self, value: bool) {
    self.allowIdentUnderscores = value
  }

  func enableWeakStrings(self, value: bool) {
    self.useWeakStrings = value
  }

  func parseToken(self) -> Token {
    if self.eof() {
      return self.eofToken()
    }
    // No further checks for eof are needed because the file always ends in a newline
    // (we add one if we detect it is missing when we read the file).
    self.skipSpace()
    self.startPos = self.pos
    char = self.readChar()
    self.checkCharValid(char)
    filepath = self.filepath!
    c = filepath.text[char.pos]
    if c == '"' || self.useWeakStrings && c == '\'' {
      return self.parseString(c)
    } else if c == '\'' {
      return self.parseAsciiChar()
    } else if isDigit(c) {
      return self.parseNumber()
    } else if c == '\\' {
      return self.parseEscapedIdent()
    }
    token = self.tryToParseUintIntOrRandType()
    if !isnull(token) {
      return token!
    }
    if self.isValidIdentChar(char) {
      return self.readIdentOrKeyword()
    }
    return self.parseNonAlphaKeyword(char)
  }

  func isValidIdentChar(self, char: Char) -> bool {
    filepath = self.filepath!
    c = filepath.text[char.pos]
    return isAsciiAlpha(filepath.text, char) || char.len > 1 ||
        self.allowIdentUnderscores && (c == '_' || c == '$')
  }

  // Skip space and comments in the input.  Do not skip newlines.
  func skipSpace(self) {
    self.rawSkipSpace()
    do {
      skippedComment = false
      if self.inputHas("//") {
        self.skipSingleLineComment()
        self.rawSkipSpace()
        skippedComment = true
      } else if self.inputHas("/*") {
        self.skipBlockComment()
        self.rawSkipSpace()
        skippedComment = true
      }
    } while skippedComment
  }

  // Skip just whitespace, not comments.
  func rawSkipSpace(self) {
    filepath = self.filepath!
    do {
      c = filepath.text[self.pos]
    } while c == ' ' || c == '\r' || c == '\t' {
      self.pos += 1
    }
  }

  // Skip the single-line comment.
  func skipSingleLineComment(self) {
    filepath = self.filepath!
    do {
      c = filepath.text[self.pos]
    } while c != '\n' {
      self.pos += 1
    }
  }

  // Skip a block comment.  They can be nested.  This can fail if a /*  or */
  // is embedded in a string, but it should work in most cases.
  func skipBlockComment(self) {
    depth = 1;
    self.pos += 2
    while !self.eof() && depth != 0 {
      if self.inputHas("/*") {
        depth += 1
        self.pos += 2
      } else if self.inputHas("*/") {
        depth -= 1
        self.pos += 2
      } else {
        self.pos += 1
      }
    }
    if depth != 0 {
      self.error("End of file during block comment");
    }
  }

  func eof(self) {
    return self.pos >= self.len
  }

  // A non-ASCII UTF-8 character will match ([\xc0-\xff][\x80-\xbf]*).
  func readChar(self) -> Char {
    char = getChar(self.filepath.text, self.pos)
    self.pos += <u32>char.len
    return char
  }

  func eofToken(self) {
    assert self.eof()
    return Token(self, TokenType.Eof, db.Location(self.filepath!, self.len, 0u32, self.line))
  }

  func error(self, msg: string) {
    self.location().error(msg)
    raise Status.InvalidArgument
  }

  func parseString(self, target) -> Token {
    s = ""
    do {
      if self.eof() {
        self.error("End of file while reading string")
      }
      char = self.readChar()
      c = self.filepath.text[char.pos]
    } while c != target {
      if c == '\\' {
        s.append(self.readEscapedChar(self.useWeakStrings))
      } else {
        for i in range(char.pos, char.pos + <u32>char.len) {
          s.append(self.filepath.text[i])
        }
      }
    }
    token = Token.newValueToken(self, s, self.location())
    if self.useWeakStrings && target == '\'' {
      token.type = TokenType.WeakString
    }
    return token
  }

  // Read an escaped character.  If in single quotes, escape single quotes,
  // otherwise escape double quotes.
  func readEscapedChar(self, singleQuotes: bool) -> u8 {
    char = self.readChar()
    c = self.filepath.text[char.pos]
    if c == 'a' {
      return '\a'
    } else if c == 'b' {
      return '\b'
    } else if c == 'e' {
      return '\e'
    } else if c == 'f' {
      return '\f'
    } else if c == 'n' {
      return '\n'
    } else if c == 'r' {
      return '\r'
    } else if c == 't' {
      return '\t'
    } else if c == 'v' {
      return '\v'
    } else if c == '\\' {
      return '\\'
    } else if c == '"' && !singleQuotes{
      return '"'
    } else if c == '\'' && singleQuotes {
      return '\''
    } else if c == '0' {
      return '\0'
    } else if c == 'x' {
      char = self.readChar()
      hi = self.filepath.text[char.pos]
      char = self.readChar()
      lo = self.filepath.text[char.pos]
      if !isHexDigit(hi) || !isHexDigit(lo) {
        self.error("Non-hex digit in hexadecimal escape sequence")
      }
      return hexToChar(hi, lo)
    }
    self.startPos = char.pos
    self.error("Invalid escape sequence")
    return '\0'  // Dummy return.
  }

  func checkCharValid(self, char: Char) {
    if !char.valid {
      self.error("Invalid character")
    }
  }

  // Returns a single quoted char as a u8 integer token.
  func parseAsciiChar(self) -> Token {
    char = self.readChar()
    self.checkCharValid(char)
    if char.len != 1 {
      self.error("Only single-byte characters can be used in single quotes")
    }
    c = self.filepath.text[char.pos]
    if c == '\\' {
      c = self.readEscapedChar(true)
    }
    self.expectChar('\'')
    return Token.newValueToken(self, c, db.Location(self.filepath!, char.pos, 1u32, self.line))
  }

  func expectChar(self, expectedChar: u8) {
    char = self.readChar()
    c = self.filepath.text[char.pos]
    if c != expectedChar {
      self.error("Expected %s, got %s" % (chr(expectedChar), chr(c)))
    }
  }

  func parseNumber(self) -> Token {
    self.pos -= 1  // Rewind to start.
    intVal = self.parseRawInteger()
    filepath = self.filepath!
    c = filepath.text[self.pos]
    if c == '.' || c == 'f' || c == 'e' {
      return self.parseFloat(intVal)
    }
    if c == 'x' && self.pos == self.startPos + 1 && filepath.text[self.startPos] == '0' {
      self.pos += 1
      intVal = self.parseHexInteger()
    }
    return self.parseIntegerSuffix(intVal)
  }

  func parseIntegerSuffix(self, intVal: db.Bigint) -> Token {
    filepath = self.filepath!
    width = 64u32 // default if there are no format specifiers
    c = filepath.text[self.pos]
    if c == 'i' || c == 'u' {
      self.pos += 1
      result = self.parseWidthSpec()
      if !result[0] {
        self.error("Invalid integer width spec")
      }
      width = result[1]
    }
    try {
      newIntVal = intVal.resize(width, true)
    } except e {
      default => self.error("Constant does not fit in integer width")
    }
    if (c == 'i') {
      try {
        newIntVal = newIntVal.cast(newIntVal.width, true, intVal.isSecret)
      } except e {
        default => self.error("Constant does not fit in integer width")
      }
    }
    return Token.newValueToken(self, newIntVal, self.location())
  }

  func parseWidthSpec(self) -> (bool, u32) {
    filepath = self.filepath!
    c = filepath.text[self.pos]
    if c < '1' || c > '9' {
      return (false, 0u32)
    }
    newWidth = self.parseRawInteger()
    if newWidth > <newWidth>0xffff {
      return (false, 0u32)
    }
    char = self.readChar()
    if self.isValidIdentChar(char) {
      return (false, 0u32)
    }
    self.pos = char.pos
    return (true, <u32>newWidth)
  }

  // Parse a raw integer.  If the first character is not a digit,
  // returns Bigint(0).  The width is set to the minimum width needed to
  // fit the unsigned integer.
  func parseRawInteger(self) {
    filepath = self.filepath!
    width = 8u32
    intVal = db.Bigint(0, width)
    do {
      c = filepath.text[self.pos]
    } while isDigit(c) || c == '_' {
      self.pos += 1
      if c != '_' {
        if (intVal << 5u32) >> 5u32 != intVal {
          width += 8
          intVal = intVal.cast(width, intVal.isSigned, intVal.isSecret, false)
        }
        intVal = (intVal * <intVal>10) + <intVal>(c - '0')
      }
    }
    return intVal.shrinkToFit()
  }

  // Count the number of 0-9 digits in the input stream.
  func countDigits(self) -> u32 {
    filepath = self.filepath!
    numDigits = 0u32
    while isDigit(filepath.text[self.pos + numDigits]) {
      numDigits += 1
    }
    return numDigits
  }

  func parseFloat(self, intVal) -> Token {
    fracVal = db.Bigint(0)
    width = 64u32
    exp = 0i32
    fracDigits = 0u32
    filepath = self.filepath!
    c = filepath.text[self.pos]
    if c == '.' {
      self.pos += 1
      fracDigits = self.countDigits()
      fracVal = self.parseRawInteger()
      c = filepath.text[self.pos]
    }
    if c == 'e' {
      self.pos += 1
      negateExp = false
      if filepath.text[self.pos] == '-' {
        self.pos += 1
        negateExp = true
      }
      if !isDigit(filepath.text[self.pos]) {
        self.error("Missing exponent after 'e' in floating point number")
      }
      exp = <i32><u32>self.parseRawInteger()
      if negateExp {
        exp = -exp
      }
      c = filepath.text[self.pos]
    }
    if c == 'f' {
      self.pos += 1
      width = <u32>self.parseRawInteger()
      if width != 32u32  && width != 64u32 {
        self.error("Only 32 and 64 bit floating point numbers are currently supported.")
      }
    }
    return self.buildFloatToken(intVal, fracVal, fracDigits, exp, width)
  }

  func buildFloatToken(self, intVal: db.Bigint, fracVal: db.Bigint, fracDigits: u32,
      exp: i32, width: u32) {
    val = <f64><u64>intVal + <f64><u64>fracVal / pow(10.0f64, fracDigits)
    val *= pow(10.0f64, exp)
    return Token.newValueToken(self, val, self.location())

    // The Rune C compiler needs o be enhanced to support floating point exponentiation.
    func pow(base, exp) {
      result = <base>1
      invert = exp < 0
      n = exp
      if invert {
        n = -exp
      }
      for i in range(n) {
        result *= base
      }
      if invert {
        return 1.0f64 / result
      }
      return result
    }
  }

  // Return the location from self.startPos to self.pos.
  func location(self) {
    return db.Location(self.filepath!, self.startPos, self.pos - self.startPos, self.line)
  }

  // Parse the hex chars, but don't parse the width spec.
  func parseHexInteger(self) -> db.Bigint {
    filepath = self.filepath!
    intVal = db.Bigint(0u1)
    width = 0
    do {
      c = filepath.text[self.pos]
    } while isHexDigit(c) || c == '_' {
      if c != '_' {
        newIntVal = intVal.resize(intVal.width + 4) << 4u32
        intVal = newIntVal | db.Bigint(hexDigit(c), newIntVal.width)
      }
      self.pos += 1
    }
    return intVal.shrinkToFit()
  }

  func parseEscapedIdent(self) -> Token {
    self.startPos = self.pos  // Don't include the slash in the name.
    filepath = self.filepath!
    do {
      char = self.readChar()
      c = filepath.text[char.pos]
    } while !isWhitespace(c) && c != '\n'
    self.pos -= 1  // Push the white space back into the input stream.
    name = filepath.text[self.startPos : self.pos]
    return Token.newValueToken(self, Sym.new(name), self.location())
  }

  // Try to parse tokens like u32, i64, and rand256.
  func tryToParseUintIntOrRandType(self) {
    pos = self.pos
    if self.tokenStartsWith("rand") {
      self.pos += 3
      type = TokenType.RandUint
    } else if self.tokenStartsWith("i") {
      type = TokenType.IntType
    } else if self.tokenStartsWith("u") {
      type = TokenType.UintType
    } else {
      return null(Token)
    }
    result = self.parseWidthSpec()
    if !result[0] {
      self.pos = pos
      return null(Token)
    }
    return Token(self, type, self.location(), value = db.Value(result[1]))
  }

  func tokenStartsWith(self, text: string) -> bool {
    if self.startPos + <u32>text.length() > self.len {
      return false
    }
    return text == self.filepath.text[self.startPos : self.startPos + <u32>text.length()]
  }

  func inputHas(self, text: string) -> bool {
    if self.pos + <u32>text.length() > self.len {
      return false
    }
    return text == self.filepath.text[self.pos : self.pos + <u32>text.length()]
  }

  func readIdentOrKeyword(self) -> Token {
    filepath = self.filepath!
    do {
      char = self.readChar()
      c = filepath.text[char.pos]
    } while isAsciiAlpha(filepath.text, char) || char.len > 1 || isDigit(c) ||
        self.allowIdentUnderscores && (c == '_' || c == '$')
    self.pos -= 1  // Push the next character back into the input stream.
    name = filepath.text[self.startPos : self.pos]
    keyword = self.keytab.lookup(name)
    if !isnull(keyword) {
      return Token.newValueToken(self, keyword!, self.location())
    }
    return Token.newValueToken(self, Sym.new(name), self.location())
  }

  // Read up to 4 characters to see if it matches a keyword.
  // Try longest to shortest.
  func parseNonAlphaKeyword(self, char: Char) -> Token {
    for i in [4, 3, 2, 1] {
      self.pos = self.startPos
      keyword = self.tryNonAlphaKeyword(i)
      if !isnull(keyword) {
        // Check to see if it is a newline.
        if i == 1 && keyword.sym.name[0] == '\n' {
          self.line += 1
        }
        return Token.newValueToken(self, keyword!, self.location())
      }
    }
    self.error("Parser error: keyword not found")
    return self.eofToken()  // Dummy return.
  }

  // See if a `len` character keyword exists in the keyword table.
  func tryNonAlphaKeyword(self, len: u64) -> Keyword? {
    for i in range(len) {
      char = self.readChar()
    }
    text = self.filepath.text[self.startPos : self.pos]
    keytab = self.keytab!
    return keytab.lookup(text)
  }
}

relation OneToOne db.Filepath Lexer cascade

unittest emptyTest {
  filepath = db.Filepath("testdata/empty", null(db.Filepath), false)
  keytab = Keytab()
  lexer = Lexer(filepath, keytab, false)
  assert lexer.len == 0
  assert lexer.eof()
  token = lexer.parseToken()
  assert token.type == TokenType.Eof
  lexer.destroy()
  println "Passed empty test"
}

unittest {
  func newLexer(text: string) {
    filepath = db.Filepath("testdata/empty", null(db.Filepath), false)
    filepath.text = text + "\n"
    keytab = Keytab()
    Keyword(keytab, "\n")
    return Lexer(filepath, keytab, false)
  }
}

unittest parseEscapedCharsTest {
  lexer = newLexer("\"\\a\\b\\e\\f\\n\\r\\t\\v\\\\\\\"\\0\\xde\\xad\"")
  token = lexer.parseToken()
  assert token.type == TokenType.String
  value = token.value!
  assert value.type == db.DatatypeType.String
  s = value.stringVal
  assert s[0] == '\x07'  // Bell.
  assert s[1] == '\x08'  // Backspace.
  assert s[2] == '\x1b'  // Escape.
  assert s[3] == '\x0c'  // Formfeed.
  assert s[4] == '\x0a'  // Newline.
  assert s[5] == '\x0d'  // Return.
  assert s[6] == '\x09'  // Tab.
  assert s[7] == '\x0b'  // Vertical tab.
  assert s[8] == '\\'
  assert s[9] == '"'
  assert s[10] == '\0'
  assert s[11] == '\xde'
  assert s[12] == '\xad'
  println "Passed escaped chars test"
}

unittest badInputTest {
  // Overlong encoding of '\0'
  lexer = newLexer("\xc0\x80")
  try {
    lexer.parseToken()
    panic "Failed invalid character test"
  } except e {
    default => println "Caught invalid character"
  }
  lexer.destroy()
  lexer = newLexer("\"\\x0g\"")
  try {
    lexer.parseToken()
    panic "Failed invalid hex escape test"
  } except e {
    default => println "Caught invalid hex escape"
  }
  lexer.destroy()
  lexer = newLexer("\"\\z\"")
  try {
    lexer.parseToken()
    panic "Failed invalid escape sequence"
  } except e {
    default => println "Caught invalid escape sequence"
  }
  lexer.destroy()
  lexer = newLexer("\"no end quote")
  try {
    lexer.parseToken()
    panic "Failed to catch unexpeced end of file"
  } except e {
    default => println "Caught unexpected end of file"
  }
  println "Passed bad input test"
}

unittest parseEscapedSingleQuotedCharsTest {
  lexer = newLexer("'\\a' '\\b' '\\e' '\\f' '\\n' '\\r' '\\t' '\\v' '\\\\' '\\'' '\\0' '\\xde' '\\xad'")
  expRes = ['\x07' /* Bell */, '\x08' /* Backspace */, '\x1b' /* Escape */, '\x0c' /* Formfeed */,
      '\x0a' /* Newline */, '\x0d' /* Return */, '\x09' /* Tab */, '\x0b' /* Vertical tab */,
      '\\', '\'', '\0', '\xde', '\xad']
  for i in range(expRes.length()) {
    token = lexer.parseToken()
    assert token.type == TokenType.Integer && token.value.intVal! == db.Bigint(expRes[i])
  }
  println "Passed escaped chars test"
}

unittest parseIntegerTest {
  lexer = newLexer("0 1u2 3i3 57896044618658097711785492504343953926634992332820282019728792003956564819949u256")
  expRes = ["0u64", "1u2", "3i3", "57896044618658097711785492504343953926634992332820282019728792003956564819949u256"]
  i = 0
  do {
    token = lexer.parseToken()
  } while !token.isKeyword("\n") {
    println "token value = ", token.value.intVal.toString()
    assert token.type == TokenType.Integer && token.value.intVal.toString() == expRes[i]
    i += 1
  }
  println "Passed parse integer test"
}

unittest parseHexTest {
  lexer = newLexer("0x0 0xau4 0x3i3 0x7fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffedu256")
  expRes = ["0u64", "au4", "3i3", "7fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffedu256"]
  for i in  range(expRes.length()) {
    token = lexer.parseToken()
    intValStr = token.value.intVal.toStringInBase(16u32)
    println "token value = ", intValStr
    assert token.type == TokenType.Integer && intValStr == expRes[i]
  }
  println "Passed parse integer test"
}

unittest parseFloatTest {
  lexer = newLexer("0. 3.14 0.999e3 2.4e-24 123456789.123456789")
  expRes = ["0.0", "3.14", "9.99e2", "2.4e-24", "1.234568e8"]
  for i in  range(expRes.length()) {
    token = lexer.parseToken()
    floatValStr = "%f" % token.value.floatVal
    println "token value = ", floatValStr
    assert token.type == TokenType.Float && floatValStr == expRes[i]
  }
  println "Passed parse float test"
}

unittest parseEscapedIdentTest {
  lexer = newLexer("\\if \\+ \\test")
  expRes = ["if", "+", "test"]
  for i in  range(expRes.length()) {
    token = lexer.parseToken()
    assert token.type == TokenType.Ident
    identStr = token.value.symVal.name
    println "token value = ", identStr
    assert identStr == expRes[i]
  }
  println "Passed parse escaped ident test"
}

unittest parseIdentTest {
  lexer = newLexer("schön a123 test")
  expRes = ["schön", "a123", "test"]
  for i in  range(expRes.length()) {
    token = lexer.parseToken()
    assert token.type == TokenType.Ident
    identStr = token.value.symVal.name
    println "token value = ", identStr
    assert identStr == expRes[i]
  }
  println "Passed parse ident test"
}

unittest enableUnderscoresTest {
  lexer = newLexer("$sch_ön $a1_23 _test")
  lexer.enableIdentUnderscores(true)
  expRes = ["$sch_ön", "$a1_23", "_test"]
  for i in  range(expRes.length()) {
    token = lexer.parseToken()
    assert token.type == TokenType.Ident
    identStr = token.value.symVal.name
    println "token value = ", identStr
    assert identStr == expRes[i]
  }
  println "Passed parse enable underscores test"
}

unittest uintIntOrRandTest {
  lexer = newLexer("u32 i6 rand1_024")
  lexer.enableIdentUnderscores(true)
  expRes = ["u32", "i6", "rand1024"]
  for i in  range(expRes.length()) {
    token = lexer.parseToken()
    width = <u32>(token.value.intVal!)
    switch token.type {
      TokenType.RandUint => str = "rand%u" % width
      TokenType.IntType => str = "i%u" % width
      TokenType.UintType => str = "u%u" % width
      default => panic "Unexpected token type"
    }
    println "token value = ", str
    assert str == expRes[i]
  }
  println "Passed u|i|rand test"
}

unittest singleLineCommentTest {
  lexer = newLexer( "// Empty line\n1 2 3 // No more on this line\n// Comment above line.\n4 5")
  lexer.enableIdentUnderscores(true)
  expRes = ["\\n", "1u64", "2u64", "3u64", "\\n", "\\n", "4u64", "5u64"]
  for i in  range(expRes.length()) {
    token = lexer.parseToken()
    switch token.type {
      TokenType.Keyword => str = "\\n"
      TokenType.Integer => str = token.value.intVal.toString()
      default => panic "Unexpected token type"
    }
    println "token value = ", str
    assert str == expRes[i]
  }
  println "Passed signleLineCommentTest"
}

unittest blockCommentTest {
  lexer = newLexer( "/* Empty /* line\n */1 */2 3 /* No more on this line*/\n/* Comment above line.\n4*/ 5")
  lexer.enableIdentUnderscores(true)
  expRes = ["2u64", "3u64", "\\n", "5u64"]
  for i in  range(expRes.length()) {
    token = lexer.parseToken()
    switch token.type {
      TokenType.Keyword => str = "\\n"
      TokenType.Integer => str = token.value.intVal.toString()
      default => panic "Unexpected token type"
    }
    println "token value = ", str
    assert str == expRes[i]
  }
  println "Passed blockCommentTest"
}
